{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  test_images  train.csv  train_images\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch, gc\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "HOME = '/data/git/shopee-product-matching'\n",
    "pdata = f'{HOME}/data/shopee-product-matching'\n",
    "!ls $pdata\n",
    "\n",
    "BS = 256\n",
    "NWKRS = 8\n",
    "DEVICE = 'cuda'\n",
    "PIN_MEMORY = True\n",
    "MAXLEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnm = 'train'\n",
    "df = pd.read_csv(f'{pdata}/{fnm}.csv')\n",
    "assert len(df) == df.posting_id.nunique()\n",
    "p_imgs = f\"{pdata}/train_images\"\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 7845.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., 42., 40., 30., 32.],\n",
       "       [42.,  0., 28., 28., 34.],\n",
       "       [40., 28.,  0., 34., 44.],\n",
       "       [30., 28., 34.,  0., 34.],\n",
       "       [32., 34., 44., 34.,  0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hamming(x1, x2): \n",
    "    x1,x2 = (bin(int(x, 16)) for x in (x1, x2))\n",
    "    return sum(o1!=o2 for o1,o2 in zip(x1,x2))\n",
    "n = 5\n",
    "hdists = np.zeros((n, n))\n",
    "for i in tqdm(range(n)):\n",
    "    for j in range(i, n):\n",
    "        x1 = df.image_phash[i]\n",
    "        x2 = df.image_phash[j]\n",
    "        hdists[i,j]=hdists[j,i]=hamming(x1, x2)\n",
    "hdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfeats = df[:5].image_phash.apply(lambda x: int(x, 16)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://leetcode.com/problems/hamming-distance/discuss/1105813/Python3-with-bit-manipulation-faster-than-99.96.\n",
    "def hammingDistance(x: int, y: int) -> int:\n",
    "    x,y=int(x),int(y)\n",
    "    n=x^y     #taking XOR of inputs to capture the difference(at bit level) between them.\n",
    "    counter=0\n",
    "    while(n):           #to count the set bits\n",
    "        counter+=1\n",
    "        n&=(n-1)\n",
    "    return counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18078.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., 42., 40., 30., 32.],\n",
       "       [42.,  0., 28., 28., 34.],\n",
       "       [40., 28.,  0., 34., 44.],\n",
       "       [30., 28., 34.,  0., 34.],\n",
       "       [32., 34., 44., 34.,  0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(hfeats)\n",
    "hdists = np.zeros((n, n))\n",
    "for i in tqdm(range(n)):\n",
    "    for j in range(i, n):\n",
    "        x1 = hfeats[i]\n",
    "        x2 = hfeats[j]\n",
    "        hdists[i,j]=hdists[j,i]=hammingDistance(x1, x2)\n",
    "        \n",
    "hdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 37., 35., 26., 25.],\n",
       "       [37.,  0., 22., 23., 26.],\n",
       "       [35., 22.,  0., 25., 34.],\n",
       "       [26., 23., 25.,  0., 29.],\n",
       "       [25., 26., 34., 29.,  0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(hfeats[:,None], metric=hammingDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hammingDistance(x, y):\n",
    "    print(x, y)\n",
    "    x,y = x.astype('uint64'),y.astype('uint64')\n",
    "    print(x, y)\n",
    "    n=np.bitwise_xor(x,y)     #taking XOR of inputs to capture the difference(at bit level) between them.\n",
    "    counter=0\n",
    "    while(n):           #to count the set bits\n",
    "        counter+=1\n",
    "        n&=(n-1)\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint64')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfeats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10707114133977572403, 12627975023471333135, 13352240572977713016,\n",
       "        9589566965408506499, 12029987587489624204], dtype=uint64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.07071141e+19] [1.2627975e+19]\n",
      "[10707114133977573376] [12627975023471333376]\n",
      "[1.07071141e+19] [1.33522406e+19]\n",
      "[10707114133977573376] [13352240572977713152]\n",
      "[1.07071141e+19] [9.58956697e+18]\n",
      "[10707114133977573376] [9589566965408505856]\n",
      "[1.07071141e+19] [1.20299876e+19]\n",
      "[10707114133977573376] [12029987587489624064]\n",
      "[1.2627975e+19] [1.33522406e+19]\n",
      "[12627975023471333376] [13352240572977713152]\n",
      "[1.2627975e+19] [9.58956697e+18]\n",
      "[12627975023471333376] [9589566965408505856]\n",
      "[1.2627975e+19] [1.20299876e+19]\n",
      "[12627975023471333376] [12029987587489624064]\n",
      "[1.33522406e+19] [9.58956697e+18]\n",
      "[13352240572977713152] [9589566965408505856]\n",
      "[1.33522406e+19] [1.20299876e+19]\n",
      "[13352240572977713152] [12029987587489624064]\n",
      "[9.58956697e+18] [1.20299876e+19]\n",
      "[9589566965408505856] [12029987587489624064]\n",
      "[1.07071141e+19] [1.07071141e+19]\n",
      "[10707114133977573376] [10707114133977573376]\n",
      "[1.2627975e+19] [1.2627975e+19]\n",
      "[12627975023471333376] [12627975023471333376]\n",
      "[1.33522406e+19] [1.33522406e+19]\n",
      "[13352240572977713152] [13352240572977713152]\n",
      "[9.58956697e+18] [9.58956697e+18]\n",
      "[9589566965408505856] [9589566965408505856]\n",
      "[1.20299876e+19] [1.20299876e+19]\n",
      "[12029987587489624064] [12029987587489624064]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., 37., 35., 26., 25.],\n",
       "       [37.,  0., 22., 23., 26.],\n",
       "       [35., 22.,  0., 25., 34.],\n",
       "       [26., 23., 25.,  0., 29.],\n",
       "       [25., 26., 34., 29.,  0.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(hfeats[:,None], metric=hammingDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
