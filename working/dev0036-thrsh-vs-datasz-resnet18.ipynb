{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch.org/vision/stable/models.html\n",
    "- https://discuss.pytorch.org/t/how-to-delete-layer-in-pretrained-model/17648/2?u=yang-zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  9 02:03:42 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   38C    P0    44W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "pcomp = f'{HOME}/input/shopee-product-matching'\n",
    "\n",
    "IMGSZ = 224\n",
    "NWKRS = 8\n",
    "BS = 32\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "PIN_MEMORY = True if DEVICE == torch.device(\"cuda\") else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getf1(x, y):\n",
    "    n = len(np.intersect1d(x, y))\n",
    "    return 2 * n / (len(x) + len(y))\n",
    "\n",
    "\n",
    "def getf1s(xs, ys):\n",
    "    return (getf1(x, y) for x, y in zip(xs, ys))\n",
    "\n",
    "\n",
    "def meanf1(xs, ys):\n",
    "    return np.mean(list(getf1s(xs, ys)))\n",
    "\n",
    "\n",
    "def get_targets(df):\n",
    "    grp2ids = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n",
    "    targets = df.label_group.map(grp2ids).values\n",
    "    return targets\n",
    "\n",
    "def preds2pids(preds, pids):\n",
    "    return [pids[o] for o in preds]\n",
    "\n",
    "\n",
    "def comb_preds(*preds):\n",
    "    return (np.unique(np.concatenate(l)) for l in zip(*preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class VDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.filepath[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transforms(img)\n",
    "        return img\n",
    "    \n",
    "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "tfms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMGSZ, IMGSZ)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def mk_dl(df):\n",
    "    ds = VDataset(df, tfms)\n",
    "    dl = DataLoader(\n",
    "        dataset=ds,\n",
    "        batch_size=BS,\n",
    "        num_workers=NWKRS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return dl\n",
    "\n",
    "# https://discuss.pytorch.org/t/how-to-delete-layer-in-pretrained-model/17648/2?u=yang-zhang\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def mk_embedder(mdl):\n",
    "    if isinstance(mdl, torchvision.models.resnet.ResNet):\n",
    "        mdl.fc = Identity()\n",
    "    if isinstance(mdl, EfficientNet):\n",
    "        def extract_feats(input_):\n",
    "            return mdl.extract_features(input_).mean(dim=(-1, -2))\n",
    "        mdl.forward = extract_feats\n",
    "    return mdl\n",
    "\n",
    "\n",
    "def mk_feats(dl, mdl):\n",
    "    device = torch.device(DEVICE)\n",
    "    mdl = mdl.to(device)\n",
    "    mdl.eval()\n",
    "    lst = []\n",
    "    for dat in tqdm(dl, total=len(dl)):\n",
    "        with torch.no_grad():\n",
    "            fts = mdl(dat.to(device))\n",
    "        lst.append(fts.cpu().detach().numpy())\n",
    "    feats = np.concatenate(lst)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "N_NBRS = 50\n",
    "CHUNK = 1024 * 4\n",
    "\n",
    "\n",
    "def mk_nnmdl(feats, n_nbrs=N_NBRS):\n",
    "    nnmdl = NearestNeighbors(N_NBRS, metric=\"cosine\")\n",
    "    nnmdl.fit(feats)\n",
    "    return nnmdl\n",
    "\n",
    "\n",
    "def get_nbrs_from_nnmdl(feats, nnmdl, sz_chunk=CHUNK):\n",
    "    n = len(feats)\n",
    "    n_nbrs = nnmdl.n_neighbors\n",
    "    dists = np.zeros((n, n_nbrs), dtype=\"float\")\n",
    "    idx = np.zeros((n, n_nbrs), dtype=\"int\")\n",
    "    n_chunks = len(feats) // sz_chunk\n",
    "    if len(feats) % sz_chunk != 0:\n",
    "        n_chunks += 1\n",
    "    for j in tqdm(range(n_chunks)):\n",
    "        a = j * sz_chunk\n",
    "        b = (j + 1) * sz_chunk\n",
    "        b = min(b, len(feats))\n",
    "        dists_, idx_ = nnmdl.kneighbors(\n",
    "            feats[\n",
    "                a:b,\n",
    "            ]\n",
    "        )\n",
    "        dists[a:b] = dists_\n",
    "        idx[a:b] = idx_\n",
    "    return dists, idx\n",
    "\n",
    "\n",
    "def get_nbrs(feats, n_nbrs=N_NBRS, sz_chunk=CHUNK):\n",
    "    nnmdl = mk_nnmdl(feats, n_nbrs)\n",
    "    dists, idx = get_nbrs_from_nnmdl(feats, nnmdl, sz_chunk)\n",
    "    return dists, idx\n",
    "\n",
    "\n",
    "def get_preds_by_thrsh(dists, idx, thrsh):\n",
    "    preds = (ind[dst < thrsh] for dst, ind in zip(dists, idx))\n",
    "    return preds\n",
    "\n",
    "\n",
    "def find_best(dists, idx, pids, targets, thrshes=np.linspace(0.,1.,num=21)):\n",
    "    f1_lst = []\n",
    "    preds_lst = []\n",
    "    for thrsh in tqdm(thrshes):\n",
    "        preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "        preds = preds2pids(preds, pids)\n",
    "        preds_lst.append(preds)\n",
    "        f1 = meanf1(preds,targets)\n",
    "        f1_lst.append(f1)\n",
    "    f1_best, thrsh_best, preds_best = sorted(zip(f1_lst, thrshes, preds_lst), reverse=True)[0]\n",
    "    res = {'f1_best': f1_best, \n",
    "           'thrsh_best': thrsh_best, \n",
    "           'preds_best': preds_best, \n",
    "           'thrshes': thrshes, \n",
    "           'f1_lst': f1_lst}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{pcomp}/train.csv')\n",
    "df['filepath'] = f\"{pcomp}/train_images/\"+df.image\n",
    "pids = df.posting_id.values\n",
    "targets = get_targets(df)\n",
    "\n",
    "dl = mk_dl(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34250, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret    249114794   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069   \n",
       "\n",
       "                                            filepath  \n",
       "0  /data/git/shopee-product-matching/input/shopee...  \n",
       "1  /data/git/shopee-product-matching/input/shopee...  \n",
       "2  /data/git/shopee-product-matching/input/shopee...  \n",
       "3  /data/git/shopee-product-matching/input/shopee...  \n",
       "4  /data/git/shopee-product-matching/input/shopee...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir(torchvision.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm2mdl = {\n",
    "    'resnet18': torchvision.models.resnet18(pretrained=True),\n",
    "#     'resnet34': torchvision.models.resnet34(pretrained=True),\n",
    "#     'resnet50': torchvision.models.resnet50(pretrained=True),\n",
    "#     'resnet101': torchvision.models.resnet101(pretrained=True),\n",
    "#     'resnet152': torchvision.models.resnet152(pretrained=True),\n",
    "#     'resnext50_32x4d': torchvision.models.resnext50_32x4d(pretrained=True),\n",
    "#     'resnext101_32x8d': torchvision.models.resnext101_32x8d(pretrained=True),\n",
    "#     \"efficientnet-b0\": EfficientNet.from_pretrained(\"efficientnet-b0\"),\n",
    "#     \"efficientnet-b1\": EfficientNet.from_pretrained(\"efficientnet-b1\"),\n",
    "#     \"efficientnet-b2\": EfficientNet.from_pretrained(\"efficientnet-b2\"),\n",
    "#     \"efficientnet-b3\": EfficientNet.from_pretrained(\"efficientnet-b3\"),\n",
    "#     \"efficientnet-b4\": EfficientNet.from_pretrained(\"efficientnet-b4\"),\n",
    "#     \"efficientnet-b5\": EfficientNet.from_pretrained(\"efficientnet-b5\"),\n",
    "#     \"efficientnet-b6\": EfficientNet.from_pretrained(\"efficientnet-b6\"),\n",
    "#     \"efficientnet-b7\": EfficientNet.from_pretrained(\"efficientnet-b7\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18 512\n"
     ]
    }
   ],
   "source": [
    "for dat in dl:\n",
    "    dat \n",
    "    break\n",
    "\n",
    "for nm,mdl in nm2mdl.items():\n",
    "    mdl = mk_embedder(mdl)\n",
    "    output = mdl(dat)\n",
    "    print(nm, output.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [01:51<00:00,  9.57it/s]\n"
     ]
    }
   ],
   "source": [
    "nm2feats = {nm: mk_feats(dl, mdl) for nm,mdl in nm2mdl.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = \"resnet18\"\n",
    "feats = nm2feats[nm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34250\n",
      "[6850, 13700, 20550, 27400, 34250]\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "print(n)\n",
    "ms = [int(n*o) for o in np.linspace(0.2, 1., 5)]\n",
    "# ms = [1000]\n",
    "print(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "m2idx = {m: sorted(np.random.choice(range(n), m, replace=False)) for m in ms}\n",
    "m2feats = {m:feats[idx] for m,idx in m2idx.items()}\n",
    "m2targets = {m:targets[idx] for m,idx in m2idx.items()}\n",
    "m2pids = {m:pids[idx] for m,idx in m2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6850: 6850, 13700: 13700, 20550: 20550, 27400: 27400, 34250: 34250}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{m:len(o) for m,o in m2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6850: 6850, 13700: 13700, 20550: 20550, 27400: 27400, 34250: 34250}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{m:len(o) for m,o in m2feats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6850: 6850, 13700: 13700, 20550: 20550, 27400: 27400, 34250: 34250}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{m:len(o) for m,o in m2targets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.28it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.23it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.41it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.18it/s]\n"
     ]
    }
   ],
   "source": [
    "m2nbrs = {m: get_nbrs(o) for m,o in m2feats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:07<00:00,  2.79it/s]\n",
      "100%|██████████| 21/21 [00:15<00:00,  1.36it/s]\n",
      "100%|██████████| 21/21 [00:22<00:00,  1.05s/it]\n",
      " 67%|██████▋   | 14/21 [00:18<00:11,  1.58s/it]"
     ]
    }
   ],
   "source": [
    "m2res = {m:find_best(*nbrs, m2pids[m], m2targets[m]) for m,nbrs in m2nbrs.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2f1 = {m:res['f1_best'] for m,res in m2res.items()}\n",
    "m2f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2thrsh = {m:res['thrsh_best'] for m,res in m2res.items()}\n",
    "\n",
    "m2thrsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m2thrsh.keys(), m2thrsh.values(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,res in m2res.items():\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.plot(res['thrshes'], res['f1_lst'])  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
