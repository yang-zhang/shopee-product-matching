{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  test_images  train.csv  train_images\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch, gc\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "HOME = '/data/git/shopee-product-matching'\n",
    "pdata = f'{HOME}/data/shopee-product-matching'\n",
    "!ls $pdata\n",
    "\n",
    "BS = 256\n",
    "NWKRS = 8\n",
    "DEVICE = 'cuda'\n",
    "PIN_MEMORY = True\n",
    "MAXLEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnm = 'train'\n",
    "df = pd.read_csv(f'{pdata}/{fnm}.csv')\n",
    "assert len(df) == df.posting_id.nunique()\n",
    "p_imgs = f\"{pdata}/train_images\"\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:55<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "class VDataset(Dataset):\n",
    "    def __init__(self, df, p_imgs, transforms):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.image[idx]\n",
    "        img_path = f\"{p_imgs}/{img_id}\"\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transforms(img)\n",
    "        return img\n",
    "\n",
    "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "tfms = transforms.Compose([\n",
    "    transforms.Resize((224,224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "ds = VDataset(df, p_imgs, tfms)\n",
    "\n",
    "dl = DataLoader(dataset=ds, \n",
    "                batch_size=BS,\n",
    "                num_workers=NWKRS,\n",
    "                pin_memory=PIN_MEMORY,\n",
    "                shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "mdlv = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "mdlv.eval()\n",
    "\n",
    "feats = np.zeros((len(ds), 1280))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        fts = mdlv.extract_features(dat.to(device)).mean(dim=(-1,-2))\n",
    "    l = len(fts)\n",
    "    feats[i:i+l,:] = fts.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34250, 5), (34250, 1280))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del dl, ds, dat, fts, mdlv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfeats = feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tensors(txt, tokenizer, maxlen):\n",
    "    tok_res = tokenizer(\n",
    "        txt, truncation=True, padding=True, max_length=maxlen\n",
    "    )\n",
    "    input_ids = tok_res[\"input_ids\"]\n",
    "    token_type_ids = tok_res[\"token_type_ids\"]\n",
    "    attention_mask = tok_res[\"attention_mask\"]\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    token_type_ids = torch.tensor(token_type_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "\n",
    "def mk_dl(tensors):\n",
    "    input_ids, token_type_ids, attention_mask = tensors\n",
    "    ds = TensorDataset(input_ids, attention_mask, token_type_ids)\n",
    "    dl = DataLoader(dataset=ds, \n",
    "                batch_size=BS,\n",
    "                num_workers=NWKRS,\n",
    "                pin_memory=PIN_MEMORY,\n",
    "                shuffle=False)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:13<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# 'bert-base-multilingual-cased',\n",
    "# 'xlm-roberta-base',\n",
    "# 'pvl/labse_bert'\n",
    "nm_mdl = 'pvl/labse_bert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(nm_mdl, do_lower_case=False)\n",
    "\n",
    "tensors = mk_tensors(list(df.title.values), tokenizer, maxlen=MAXLEN)\n",
    "\n",
    "dl = mk_dl(tensors)\n",
    "\n",
    "mdlt = AutoModel.from_pretrained(nm_mdl).to(device)\n",
    "mdlt.eval()\n",
    "\n",
    "feats = np.zeros((len(df), 768))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = (o.to(device) for o in dat)\n",
    "        output = mdlt(*dat)\n",
    "        fts = output.last_hidden_state\n",
    "        fts = fts.mean(dim=-2)\n",
    "        l = len(fts)\n",
    "        feats[i:i+l,:] = fts.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del dl, dat, fts, mdlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34250, 5), (34250, 768))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeats = feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
