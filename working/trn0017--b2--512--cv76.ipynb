{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfx = \"trn0017\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Sat Apr 17 16:12:41 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    23W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution\n",
    "- https://www.kaggle.com/zzy990106/b0-bert-cv0-9\n",
    "- https://github.com/yang-zhang/product_category/blob/dev/notebooks/transformer_20210307E1--pin_memory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "p_out = f'{HOME}/output/{prfx}'\n",
    "!mkdir -p {p_out}\n",
    "p_prp = f'{HOME}/output/prep002'\n",
    "\n",
    "FOLD = 0\n",
    "FP16 = False\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/src\")\n",
    "\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pl_model import ShpModel, ShpDataModule\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--imgsz\",\n",
    "    help=\"Image size.\",\n",
    "    type=int,\n",
    "    default=224,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--train_batch_size\",\n",
    "    help=\"How many samples per batch to load for train dataloader.\",\n",
    "    type=int,\n",
    "    default=64,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_batch_size\",\n",
    "    help=\"How many samples per batch to load for validation dataloader.\",\n",
    "    type=int,\n",
    "    default=128,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataloader_num_workers\",\n",
    "    help=\"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\",\n",
    "    type=int,\n",
    "    default=8,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pin_memory\",\n",
    "    help=\"Wether to use pin_memory in pytorch dataloader. If True, the data loader will copy Tensors into CUDA pinned memory before returning them.\",\n",
    "    action=\"store_true\",\n",
    ")\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = ShpModel.add_model_specific_args(parser)\n",
    "args_list = [\n",
    "    '--default_root_dir', p_out,\n",
    "    '--kernel-type', '',\n",
    "    '--enet-type', 'tf_efficientnet_b2_ns',\n",
    "    '--imgsz', '512',\n",
    "    \"--train_batch_size\", '64',\n",
    "    \"--val_batch_size\", '128',]\n",
    "\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        posting_id                                 image  \\\n",
       "0      0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "\n",
       "        image_phash                                              title  \\\n",
       "0  94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "\n",
       "   label_group                                           filepath  fold  \n",
       "0    249114794  /data/git/shopee-product-matching/input/shopee...     0  \n",
       "1   2937985045  /data/git/shopee-product-matching/input/shopee...     2  \n",
       "2   2395904891  /data/git/shopee-product-matching/input/shopee...     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23292, 8) (5823, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{p_prp}/df_train.csv\")\n",
    "display(df.head(3))\n",
    "dftrn = df[df.fold!=FOLD].copy()\n",
    "dfval = df[df.fold==FOLD].copy()\n",
    "print(dftrn.shape, dfval.shape)\n",
    "\n",
    "data_module = ShpDataModule(\n",
    "    dftrn=dftrn,\n",
    "    dfval=dfval,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    pin_memory=args.pin_memory,    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.setup()\n",
    "data_module.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shpmodel = ShpModel(\n",
    "    kernel_type=args.kernel_type,\n",
    "    enet_type=args.enet_type,\n",
    "    learning_rate=args.learning_rate,\n",
    "    num_classes=data_module.num_classes,\n",
    "    margins=data_module.margins,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dl = data_module.train_dataloader()\n",
    "for dat in dl:\n",
    "    dat\n",
    "    break\n",
    "feat = shpmodel(dat[0])\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         fast_dev_run=True,\n",
    "                                        max_epochs=30,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_accu', patience=2)],\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                        precision=16 if FP16 else 32,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                      | Params\n",
      "-------------------------------------------------------\n",
      "0 | model    | Effnet_Landmark           | 22.8 M\n",
      "1 | arc      | ArcFaceLossAdaptiveMargin | 0     \n",
      "2 | accuracy | Accuracy                  | 0     \n",
      "-------------------------------------------------------\n",
      "22.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.8 M    Total params\n",
      "91.253    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/shopee/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe9c895ad934b86900cd7e8966b4b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer.fit(shpmodel, data_module)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 262M Apr 17 17:36 '/data/git/shopee-product-matching/output/trn0017/tensorboard_csv/1_1/checkpoints/epoch=22-step=8371.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_out}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 17 17:36:45 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    48W / 300W |   1596MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      6946      C   /data/anaconda3/envs/shopee/bin/python      1585MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "p_out = f'{HOME}/output/{prfx}'\n",
    "p_prp = f'{HOME}/output/prep002'\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/src\")\n",
    "\n",
    "import torch\n",
    "from final import enet_arcface_FINAL, load_model\n",
    "from pl_model import ShpModel\n",
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "shpmodel = ShpModel.load_from_checkpoint(f'{HOME}/output/{prfx}/tensorboard_csv/1_1/checkpoints/epoch=22-step=8371.ckpt')\n",
    "out_dim = shpmodel.num_classes\n",
    "\n",
    "\n",
    "model = enet_arcface_FINAL(args.enet_type, out_dim=out_dim).to(device)\n",
    "model = load_model(model, shpmodel)\n",
    "model = model.to(device)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getf1(x, y):\n",
    "    n = len(np.intersect1d(x, y))\n",
    "    return 2 * n / (len(x) + len(y))\n",
    "\n",
    "\n",
    "def getf1s(xs, ys):\n",
    "    return (getf1(x, y) for x, y in zip(xs, ys))\n",
    "\n",
    "\n",
    "def meanf1(xs, ys):\n",
    "    return np.mean(list(getf1s(xs, ys)))\n",
    "\n",
    "\n",
    "def get_targets(df):\n",
    "    grp2ids = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n",
    "    targets = df.label_group.map(grp2ids)\n",
    "    return targets\n",
    "\n",
    "def preds2pids(preds, pids):\n",
    "    return [pids[o] for o in preds]\n",
    "\n",
    "\n",
    "def comb_preds(*preds):\n",
    "    return (np.unique(np.concatenate(l)) for l in zip(*preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>train_1802986387</td>\n",
       "      <td>00144a49c56599d45354a1c28104c039.jpg</td>\n",
       "      <td>f815c9bb833ab4c8</td>\n",
       "      <td>Jubah anak size 1-12 thn</td>\n",
       "      <td>1835033137</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>train_1806152124</td>\n",
       "      <td>0014f61389cbaa687a58e38a97b6383d.jpg</td>\n",
       "      <td>eea7e1c0c04da33d</td>\n",
       "      <td>KULOT PLISKET SALUR /CANDY PLISKET /WISH KULOT...</td>\n",
       "      <td>1565741687</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>train_3009013664</td>\n",
       "      <td>0027aaf8dd8bdbf0e4f2c19024e436cf.jpg</td>\n",
       "      <td>b3cccc26cc3333cc</td>\n",
       "      <td>MARKS &amp; SPENCER - Rose Hand &amp; Body Lotion 250 ml</td>\n",
       "      <td>1574620312</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        posting_id                                 image  \\\n",
       "0      6  train_1802986387  00144a49c56599d45354a1c28104c039.jpg   \n",
       "1      7  train_1806152124  0014f61389cbaa687a58e38a97b6383d.jpg   \n",
       "2     16  train_3009013664  0027aaf8dd8bdbf0e4f2c19024e436cf.jpg   \n",
       "\n",
       "        image_phash                                              title  \\\n",
       "0  f815c9bb833ab4c8                           Jubah anak size 1-12 thn   \n",
       "1  eea7e1c0c04da33d  KULOT PLISKET SALUR /CANDY PLISKET /WISH KULOT...   \n",
       "2  b3cccc26cc3333cc   MARKS & SPENCER - Rose Hand & Body Lotion 250 ml   \n",
       "\n",
       "   label_group                                           filepath  \n",
       "0   1835033137  /data/git/shopee-product-matching/input/shopee...  \n",
       "1   1565741687  /data/git/shopee-product-matching/input/shopee...  \n",
       "2   1574620312  /data/git/shopee-product-matching/input/shopee...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{p_prp}/df_valid.csv\")\n",
    "pids = df.posting_id.values\n",
    "targets = get_targets(df)\n",
    "\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:36<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tfms_trn, tfms_val = get_transforms(args.imgsz)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "feats = np.zeros((len(ds), 512))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        feat,_ = model(dat)\n",
    "        l = len(feat)\n",
    "        feats[i : i + l, :] = feat.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "N_NBRS = 50\n",
    "CHUNK = 1024 * 4\n",
    "\n",
    "\n",
    "def mk_nnmdl(feats, n_nbrs=N_NBRS):\n",
    "    nnmdl = NearestNeighbors(N_NBRS, metric=\"cosine\")\n",
    "    nnmdl.fit(feats)\n",
    "    return nnmdl\n",
    "\n",
    "\n",
    "def get_nbrs_from_nnmdl(feats, nnmdl, sz_chunk=CHUNK):\n",
    "    n = len(feats)\n",
    "    n_nbrs = nnmdl.n_neighbors\n",
    "    dists = np.zeros((n, n_nbrs), dtype=\"float\")\n",
    "    idx = np.zeros((n, n_nbrs), dtype=\"int\")\n",
    "    n_chunks = len(feats) // sz_chunk\n",
    "    if len(feats) % sz_chunk != 0:\n",
    "        n_chunks += 1\n",
    "    for j in tqdm(range(n_chunks)):\n",
    "        a = j * sz_chunk\n",
    "        b = (j + 1) * sz_chunk\n",
    "        b = min(b, len(feats))\n",
    "        dists_, idx_ = nnmdl.kneighbors(\n",
    "            feats[\n",
    "                a:b,\n",
    "            ]\n",
    "        )\n",
    "        dists[a:b] = np.array(dists_)\n",
    "        idx[a:b] = np.array(idx_)\n",
    "    return dists, idx\n",
    "\n",
    "\n",
    "def get_nbrs(feats, n_nbrs=N_NBRS, sz_chunk=CHUNK):\n",
    "    nnmdl = mk_nnmdl(feats, n_nbrs)\n",
    "    dists, idx = get_nbrs_from_nnmdl(feats, nnmdl, sz_chunk)\n",
    "    return dists, idx\n",
    "\n",
    "\n",
    "def get_preds_by_thrsh(dists, idx, thrsh):\n",
    "    preds = (ind[dst < thrsh] for dst, ind in zip(dists, idx))\n",
    "    return preds\n",
    "\n",
    "\n",
    "def find_best(dists, idx, thrshes=np.linspace(0.,1.,num=21)):\n",
    "    f1_lst = []\n",
    "    preds_lst = []\n",
    "    for thrsh in tqdm(thrshes):\n",
    "        preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "        preds = preds2pids(preds, pids)\n",
    "        preds_lst.append(preds)\n",
    "        f1 = meanf1(preds,targets)\n",
    "        f1_lst.append(f1)\n",
    "    f1_best, thrsh_best, preds_best = sorted(zip(f1_lst, thrshes, preds_lst), reverse=True)[0]\n",
    "    res = {'f1_best': f1_best, \n",
    "           'thrsh_best': thrsh_best, \n",
    "           'preds_best': preds_best, \n",
    "           'thrshes': thrshes, \n",
    "           'f1_lst': f1_lst}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "nbrs = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:04<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767, 0.55 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dists, idx = nbrs\n",
    "res = find_best(dists, idx)\n",
    "print(f\"{res['f1_best']:.3f}, {res['thrsh_best']:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.plot(res['thrshes'], res['f1_lst'])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_v = res['preds_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669570316824722"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds_v, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
