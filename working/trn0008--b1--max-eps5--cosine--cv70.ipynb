{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfx = \"trn0008\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Mon Apr  5 13:57:39 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    25W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution\n",
    "- https://www.kaggle.com/zzy990106/b0-bert-cv0-9\n",
    "- https://github.com/yang-zhang/product_category/blob/dev/notebooks/transformer_20210307E1--pin_memory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "p_out = f'{HOME}/output/{prfx}'\n",
    "!mkdir -p {p_out}\n",
    "p_prp = f'{HOME}/output/prep002'\n",
    "\n",
    "FOLD = 0\n",
    "FP16 = True\n",
    "MAX_EPS = 5\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/src\")\n",
    "\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pl_model import ShpModel, ShpDataModule\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--imgsz\",\n",
    "    help=\"Image size.\",\n",
    "    type=int,\n",
    "    default=224,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--train_batch_size\",\n",
    "    help=\"How many samples per batch to load for train dataloader.\",\n",
    "    type=int,\n",
    "    default=64,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_batch_size\",\n",
    "    help=\"How many samples per batch to load for validation dataloader.\",\n",
    "    type=int,\n",
    "    default=128,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataloader_num_workers\",\n",
    "    help=\"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\",\n",
    "    type=int,\n",
    "    default=8,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pin_memory\",\n",
    "    help=\"Wether to use pin_memory in pytorch dataloader. If True, the data loader will copy Tensors into CUDA pinned memory before returning them.\",\n",
    "    action=\"store_true\",\n",
    ")\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = ShpModel.add_model_specific_args(parser)\n",
    "args_list = [\n",
    "    '--default_root_dir', p_out,\n",
    "    '--kernel-type', '',\n",
    "    '--enet-type', 'tf_efficientnet_b1_ns',\n",
    "    '--imgsz', '224',\n",
    "    \"--train_batch_size\", '64',\n",
    "    \"--val_batch_size\", '128',]\n",
    "\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        posting_id                                 image  \\\n",
       "0      0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "\n",
       "        image_phash                                              title  \\\n",
       "0  94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "\n",
       "   label_group                                           filepath  fold  \n",
       "0    249114794  /data/git/shopee-product-matching/input/shopee...     0  \n",
       "1   2937985045  /data/git/shopee-product-matching/input/shopee...     2  \n",
       "2   2395904891  /data/git/shopee-product-matching/input/shopee...     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23292, 8) (5823, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{p_prp}/df_train.csv\")\n",
    "display(df.head(3))\n",
    "dftrn = df[df.fold!=FOLD].copy()\n",
    "dfval = df[df.fold==FOLD].copy()\n",
    "print(dftrn.shape, dfval.shape)\n",
    "\n",
    "data_module = ShpDataModule(\n",
    "    dftrn=dftrn,\n",
    "    dfval=dfval,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    pin_memory=args.pin_memory,    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.setup()\n",
    "data_module.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shpmodel = ShpModel(\n",
    "    kernel_type=args.kernel_type,\n",
    "    enet_type=args.enet_type,\n",
    "    learning_rate=args.learning_rate,\n",
    "    num_classes=data_module.num_classes,\n",
    "    margins=data_module.margins,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dl = data_module.train_dataloader()\n",
    "for dat in dl:\n",
    "    dat\n",
    "    break\n",
    "feat = shpmodel(dat[0])\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=2, \n",
    "#                                         fast_dev_run=True,\n",
    "                                        max_epochs=MAX_EPS,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_accu')],\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                        precision=16 if FP16 else 32,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                      | Params\n",
      "-------------------------------------------------------\n",
      "0 | model    | Effnet_Landmark           | 21.6 M\n",
      "1 | arc      | ArcFaceLossAdaptiveMargin | 0     \n",
      "2 | accuracy | Accuracy                  | 0     \n",
      "-------------------------------------------------------\n",
      "21.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.6 M    Total params\n",
      "86.239    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/shopee/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a2b6883e33459aa0f0c1405c329f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer.fit(shpmodel, data_module)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 01:46 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 14:16 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/1_1/checkpoints/epoch=5-step=1820.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_out}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  5 14:16:40 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    52W / 300W |   1602MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     19002      C   /data/anaconda3/envs/shopee/bin/python      1591MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_trained = p_out\n",
    "imgsz = args.imgsz\n",
    "enet_type = args.enet_type\n",
    "\n",
    "import pandas as pd\n",
    "from pl_model import ShpModel\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from final import enet_arcface_FINAL, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 01:46 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 14:16 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/1_1/checkpoints/epoch=5-step=1820.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_trained}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = f'{p_trained}/tensorboard_csv/1_1/checkpoints/epoch=5-step=1820.ckpt'\n",
    "shpmodel = ShpModel.load_from_checkpoint(ckpt)\n",
    "out_dim = shpmodel.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = enet_arcface_FINAL(enet_type, out_dim=out_dim).to(device)\n",
    "model = load_model(model, shpmodel)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(f'{p_prp}/df_valid.csv')\n",
    "\n",
    "pids = df.posting_id.values\n",
    "\n",
    "tfms_trn, tfms_val = get_transforms(imgsz)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dat in dl:\n",
    "    dat = dat.to(device)\n",
    "    with torch.no_grad():\n",
    "        feat,_ = model(dat)\n",
    "    break\n",
    "\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:17<00:00,  9.39it/s]\n"
     ]
    }
   ],
   "source": [
    "feats = np.zeros((len(ds), feat.shape[1]))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        feat,_ = model(dat)\n",
    "        l = len(feat)\n",
    "        feats[i : i + l, :] = feat.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5135, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import meanf1, get_targets, get_preds_by_thrsh, preds2pids\n",
    "from neighbor import get_nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 5135\n"
     ]
    }
   ],
   "source": [
    "dists, idx = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8654118180274963, -1.1920928955078125e-06)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.max(), dists.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_preds_by_thrsh(dists, idx, thrsh=.6)\n",
    "preds = preds2pids(preds, pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5476245734503095"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41 0.42 0.43\n",
      " 0.44 0.45 0.46 0.47 0.48 0.49 0.5 ]\n"
     ]
    }
   ],
   "source": [
    "thrshes = np.linspace(.3,.5,num=21)\n",
    "print(thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:18<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_lst = []\n",
    "for thrsh in tqdm(thrshes):\n",
    "    preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "    preds = preds2pids(preds, pids)\n",
    "    f1_lst.append(meanf1(preds,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5c62c5ec10>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(thrshes, f1_lst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(dists, idx, thrshes = np.linspace(.5,.7,num=21)):\n",
    "    f1_lst = []\n",
    "    preds_lst = []\n",
    "    for thrsh in tqdm(thrshes):\n",
    "        preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "        preds = preds2pids(preds, pids)\n",
    "        preds_lst.append(preds)\n",
    "        f1 = meanf1(preds,targets)\n",
    "        f1_lst.append(f1)\n",
    "    f1_best, thrsh_best, preds_best = sorted(zip(f1_lst, thrshes, preds_lst), reverse=True)[0]\n",
    "    return f1_best, thrsh_best, preds_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:19<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_best, thrsh_best, preds_best = find_best(dists, idx, thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7057393226404051, 0.39)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best, thrsh_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(f'{p_prp}/df_train.csv')\n",
    "\n",
    "pids = df.posting_id.values\n",
    "\n",
    "tfms_trn, tfms_val = get_transforms(imgsz)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 910/910 [01:30<00:00, 10.01it/s]\n"
     ]
    }
   ],
   "source": [
    "feats = np.zeros((len(ds), feat.shape[1]))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        feat,_ = model(dat)\n",
    "        l = len(feat)\n",
    "        feats[i : i + l, :] = feat.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29115, 512)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 29115\n"
     ]
    }
   ],
   "source": [
    "dists, idx = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_preds_by_thrsh(dists, idx, thrsh=.6)\n",
    "preds = preds2pids(preds, pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3690178583556262"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:18<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_best, thrsh_best, preds_best = find_best(dists, idx, thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7057393226404051, 0.39)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best, thrsh_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/1_1/checkpoints/epoch=5-step=1820.ckpt'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {ckpt} {p_trained}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
