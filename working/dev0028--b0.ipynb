{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Thu Apr  1 13:08:53 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    22W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution\n",
    "- https://www.kaggle.com/zzy990106/b0-bert-cv0-9\n",
    "- https://github.com/yang-zhang/product_category/blob/dev/notebooks/transformer_20210307E1--pin_memory.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "p_out = f'{HOME}/output/dev0028'\n",
    "!mkdir -p {p_out}\n",
    "p_prp = f'{HOME}/output/prep001/train_prep.csv'\n",
    "\n",
    "FOLD = 0\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/src\")\n",
    "\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pl_model import ShpModel, ShpDataModule\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--train_batch_size\",\n",
    "    help=\"How many samples per batch to load for train dataloader.\",\n",
    "    type=int,\n",
    "    default=64,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_batch_size\",\n",
    "    help=\"How many samples per batch to load for validation dataloader.\",\n",
    "    type=int,\n",
    "    default=128,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataloader_num_workers\",\n",
    "    help=\"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\",\n",
    "    type=int,\n",
    "    default=8,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pin_memory\",\n",
    "    help=\"Wether to use pin_memory in pytorch dataloader. If True, the data loader will copy Tensors into CUDA pinned memory before returning them.\",\n",
    "    action=\"store_true\",\n",
    ")\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = ShpModel.add_model_specific_args(parser)\n",
    "args_list = [\n",
    "    '--default_root_dir', p_out,\n",
    "    '--kernel-type', '',\n",
    "    '--enet-type', 'tf_efficientnet_b0_ns',\n",
    "\n",
    "]\n",
    "\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>fold</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "\n",
       "                                               title  label_group  fold  \\\n",
       "0                          Paper Bag Victoria Secret    249114794     0   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045     2   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891     0   \n",
       "\n",
       "                                            filepath  \n",
       "0  /data/git/shopee-product-matching/input/shopee...  \n",
       "1  /data/git/shopee-product-matching/input/shopee...  \n",
       "2  /data/git/shopee-product-matching/input/shopee...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(p_prp)\n",
    "display(df.head(3))\n",
    "dftrn = df[df.fold!=FOLD].copy()\n",
    "dfval = df[df.fold==FOLD].copy()\n",
    "dftrn.shape, dfval.shape\n",
    "\n",
    "data_module = ShpDataModule(\n",
    "    dftrn=dftrn,\n",
    "    dfval=dfval,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    pin_memory=args.pin_memory,    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11014"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.setup()\n",
    "data_module.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b0_ns-c0e6a31c.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/tf_efficientnet_b0_ns-c0e6a31c.pth\n"
     ]
    }
   ],
   "source": [
    "shpmodel = ShpModel(\n",
    "    kernel_type=args.kernel_type,\n",
    "    enet_type=args.enet_type,\n",
    "    learning_rate=args.learning_rate,\n",
    "    num_classes=data_module.num_classes,\n",
    "    margins=data_module.margins,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dl = data_module.train_dataloader()\n",
    "for dat in dl:\n",
    "    dat\n",
    "    break\n",
    "feat = shpmodel(dat[0])\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=2, \n",
    "#                                         fast_dev_run=True,\n",
    "                                        max_epochs=50,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_loss')],\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                      | Params\n",
      "-------------------------------------------------------\n",
      "0 | model    | Effnet_Landmark           | 21.6 M\n",
      "1 | arc      | ArcFaceLossAdaptiveMargin | 0     \n",
      "2 | accuracy | Accuracy                  | 0     \n",
      "-------------------------------------------------------\n",
      "21.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.6 M    Total params\n",
      "86.324    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/shopee/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9dc21fcf144743ab8027726cf5dd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer.fit(shpmodel, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/shopee-product-matching/output/dev0028/\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/1_1\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/1_1/checkpoints\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/1_1/checkpoints/epoch=28-step=12440.ckpt\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/0_0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/0_0/checkpoints\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/0_0/checkpoints/epoch=22-step=9866.ckpt\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_1\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_1/metrics.csv\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_1/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_0/metrics.csv\r\n",
      "/data/git/shopee-product-matching/output/dev0028/csv/version_0/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1/events.out.tfevents.1617282548.ip-10-0-3-247.6113.0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0/events.out.tfevents.1617224593.ip-10-0-3-247.22856.0\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_1/events.out.tfevents.1617282548.ip-10-0-3-247.6113.0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0/hparams.yaml\r\n",
      "/data/git/shopee-product-matching/output/dev0028/tensorboard/version_0/events.out.tfevents.1617224593.ip-10-0-3-247.22856.0\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 736M Mar 31 22:45 '/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/0_0/checkpoints/epoch=22-step=9866.ckpt'\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  1 15:07 '/data/git/shopee-product-matching/output/dev0028/tensorboard_csv/1_1/checkpoints/epoch=28-step=12440.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_out}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  1 15:07:52 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    47W / 300W |   1632MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      6113      C   /data/anaconda3/envs/shopee/bin/python      1621MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import meanf1, get_targets, get_preds_by_thrsh, preds2pids\n",
    "from neighbor import get_nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "shpmodel = ShpModel.load_from_checkpoint(f'{p_out}/tensorboard_csv/1_1/checkpoints/epoch=28-step=12440.ckpt')\n",
    "shpmodel = shpmodel.eval()\n",
    "shpmodel = shpmodel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(p_prp)\n",
    "\n",
    "pids = df.posting_id.values\n",
    "\n",
    "tfms_trn, tfms_val = get_transforms(224)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dat in dl:\n",
    "    dat = dat.to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = shpmodel(dat)\n",
    "    break\n",
    "\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:43<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "feats = np.zeros((len(ds), feat.shape[1]))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        output = shpmodel(dat)\n",
    "        l = len(output)\n",
    "        feats[i : i + l, :] = output.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34250, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 32768\n",
      "chunk 32768 to 34250\n"
     ]
    }
   ],
   "source": [
    "dists, idx = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_preds_by_thrsh(dists, idx, thrsh=1.)\n",
    "preds = preds2pids(preds, pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66308454989744"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3  1.31 1.32 1.33 1.34 1.35 1.36 1.37 1.38 1.39 1.4  1.41 1.42 1.43\n",
      " 1.44 1.45 1.46 1.47 1.48 1.49 1.5 ]\n"
     ]
    }
   ],
   "source": [
    "thrshes = np.linspace(1.3,1.5,num=21)\n",
    "print(thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "f1_lst = []\n",
    "for thrsh in tqdm(thrshes):\n",
    "    preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "    preds = preds2pids(preds, pids)\n",
    "    f1_lst.append(meanf1(preds,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4125139450>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(thrshes, f1_lst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(dists, idx, thrshes = np.linspace(1.75,2.25,num=11)):\n",
    "    f1_lst = []\n",
    "    preds_lst = []\n",
    "    for thrsh in tqdm(thrshes):\n",
    "        preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "        preds = preds2pids(preds, pids)\n",
    "        preds_lst.append(preds)\n",
    "        f1 = meanf1(preds,targets)\n",
    "        f1_lst.append(f1)\n",
    "    f1_best, thrsh_best, preds_best = sorted(zip(f1_lst, thrshes, preds_lst), reverse=True)[0]\n",
    "    return f1_best, thrsh_best, preds_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:24<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "f1_best, thrsh_best, preds_best = find_best(dists, idx, thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7404599333539686, 1.3900000000000001)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best, thrsh_best"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!cp /data/git/shopee-product-matching/output/dev0027/tensorboard_csv/0_0/checkpoints/epoch=21-step=9437.ckpt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
