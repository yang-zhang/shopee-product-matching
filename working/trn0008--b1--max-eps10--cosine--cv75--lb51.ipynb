{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfx = \"trn0008\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "Mon Apr  5 01:08:13 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    47W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/haqishen/Google-Landmark-Recognition-2020-3rd-Place-Solution\n",
    "- https://www.kaggle.com/zzy990106/b0-bert-cv0-9\n",
    "- https://github.com/yang-zhang/product_category/blob/dev/notebooks/transformer_20210307E1--pin_memory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/shopee-product-matching\"\n",
    "p_out = f'{HOME}/output/{prfx}'\n",
    "!mkdir -p {p_out}\n",
    "p_prp = f'{HOME}/output/prep002'\n",
    "\n",
    "FOLD = 0\n",
    "FP16 = True\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/src\")\n",
    "\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pl_model import ShpModel, ShpDataModule\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--imgsz\",\n",
    "    help=\"Image size.\",\n",
    "    type=int,\n",
    "    default=224,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--train_batch_size\",\n",
    "    help=\"How many samples per batch to load for train dataloader.\",\n",
    "    type=int,\n",
    "    default=64,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_batch_size\",\n",
    "    help=\"How many samples per batch to load for validation dataloader.\",\n",
    "    type=int,\n",
    "    default=128,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataloader_num_workers\",\n",
    "    help=\"How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\",\n",
    "    type=int,\n",
    "    default=8,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pin_memory\",\n",
    "    help=\"Wether to use pin_memory in pytorch dataloader. If True, the data loader will copy Tensors into CUDA pinned memory before returning them.\",\n",
    "    action=\"store_true\",\n",
    ")\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = ShpModel.add_model_specific_args(parser)\n",
    "args_list = [\n",
    "    '--default_root_dir', p_out,\n",
    "    '--kernel-type', '',\n",
    "    '--enet-type', 'tf_efficientnet_b1_ns',\n",
    "    '--imgsz', '224',\n",
    "    \"--train_batch_size\", '64',\n",
    "    \"--val_batch_size\", '128',]\n",
    "\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>/data/git/shopee-product-matching/input/shopee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        posting_id                                 image  \\\n",
       "0      0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "\n",
       "        image_phash                                              title  \\\n",
       "0  94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "\n",
       "   label_group                                           filepath  fold  \n",
       "0    249114794  /data/git/shopee-product-matching/input/shopee...     0  \n",
       "1   2937985045  /data/git/shopee-product-matching/input/shopee...     2  \n",
       "2   2395904891  /data/git/shopee-product-matching/input/shopee...     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23292, 8) (5823, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{p_prp}/df_train.csv\")\n",
    "display(df.head(3))\n",
    "dftrn = df[df.fold!=FOLD].copy()\n",
    "dfval = df[df.fold==FOLD].copy()\n",
    "print(dftrn.shape, dfval.shape)\n",
    "\n",
    "data_module = ShpDataModule(\n",
    "    dftrn=dftrn,\n",
    "    dfval=dfval,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    pin_memory=args.pin_memory,    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9369"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.setup()\n",
    "data_module.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shpmodel = ShpModel(\n",
    "    kernel_type=args.kernel_type,\n",
    "    enet_type=args.enet_type,\n",
    "    learning_rate=args.learning_rate,\n",
    "    num_classes=data_module.num_classes,\n",
    "    margins=data_module.margins,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dl = data_module.train_dataloader()\n",
    "for dat in dl:\n",
    "    dat\n",
    "    break\n",
    "feat = shpmodel(dat[0])\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=2, \n",
    "#                                         fast_dev_run=True,\n",
    "                                        max_epochs=10,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_accu')],\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                        precision=16 if FP16 else 32,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                      | Params\n",
      "-------------------------------------------------------\n",
      "0 | model    | Effnet_Landmark           | 21.6 M\n",
      "1 | arc      | ArcFaceLossAdaptiveMargin | 0     \n",
      "2 | accuracy | Accuracy                  | 0     \n",
      "-------------------------------------------------------\n",
      "21.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.6 M    Total params\n",
      "86.239    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/shopee/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cdc8b40d324abb915f3b1bf6d333de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer.fit(shpmodel, data_module)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!find $p_out/tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 01:46 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_out}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  5 01:46:04 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    48W / 300W |   1604MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     18747      C   /data/anaconda3/envs/shopee/bin/python      1593MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_trained = p_out\n",
    "imgsz = args.imgsz\n",
    "enet_type = args.enet_type\n",
    "\n",
    "import pandas as pd\n",
    "from pl_model import ShpModel\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from final import enet_arcface_FINAL, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 248M Apr  5 01:46 '/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl {p_trained}/tensorboard_csv/*/checkpoints/*.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = f'{p_trained}/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'\n",
    "shpmodel = ShpModel.load_from_checkpoint(ckpt)\n",
    "out_dim = shpmodel.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = enet_arcface_FINAL(enet_type, out_dim=out_dim).to(device)\n",
    "model = load_model(model, shpmodel)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(f'{p_prp}/df_valid.csv')\n",
    "\n",
    "pids = df.posting_id.values\n",
    "\n",
    "tfms_trn, tfms_val = get_transforms(imgsz)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dat in dl:\n",
    "    dat = dat.to(device)\n",
    "    with torch.no_grad():\n",
    "        feat,_ = model(dat)\n",
    "    break\n",
    "\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:17<00:00,  9.40it/s]\n"
     ]
    }
   ],
   "source": [
    "feats = np.zeros((len(ds), feat.shape[1]))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        feat,_ = model(dat)\n",
    "        l = len(feat)\n",
    "        feats[i : i + l, :] = feat.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5135, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import meanf1, get_targets, get_preds_by_thrsh, preds2pids\n",
    "from neighbor import get_nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 5135\n"
     ]
    }
   ],
   "source": [
    "dists, idx = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8771424293518066, -1.1920928955078125e-06)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.max(), dists.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_preds_by_thrsh(dists, idx, thrsh=.6)\n",
    "preds = preds2pids(preds, pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7540571862420854"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63\n",
      " 0.64 0.65 0.66 0.67 0.68 0.69 0.7 ]\n"
     ]
    }
   ],
   "source": [
    "thrshes = np.linspace(.5,.7,num=21)\n",
    "print(thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.16it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_lst = []\n",
    "for thrsh in tqdm(thrshes):\n",
    "    preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "    preds = preds2pids(preds, pids)\n",
    "    f1_lst.append(meanf1(preds,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0e23c02f50>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(thrshes, f1_lst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(dists, idx, thrshes = np.linspace(.5,.7,num=21)):\n",
    "    f1_lst = []\n",
    "    preds_lst = []\n",
    "    for thrsh in tqdm(thrshes):\n",
    "        preds = get_preds_by_thrsh(dists, idx, thrsh)\n",
    "        preds = preds2pids(preds, pids)\n",
    "        preds_lst.append(preds)\n",
    "        f1 = meanf1(preds,targets)\n",
    "        f1_lst.append(f1)\n",
    "    f1_best, thrsh_best, preds_best = sorted(zip(f1_lst, thrshes, preds_lst), reverse=True)[0]\n",
    "    return f1_best, thrsh_best, preds_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.15it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_best, thrsh_best, preds_best = find_best(dists, idx, thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7541973503472799, 0.62)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best, thrsh_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ShopeeDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(f'{p_prp}/df_train.csv')\n",
    "\n",
    "pids = df.posting_id.values\n",
    "\n",
    "tfms_trn, tfms_val = get_transforms(imgsz)\n",
    "ds = ShopeeDataset(df, mode=\"test\", transform=tfms_val)\n",
    "dl = DataLoader(ds,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 910/910 [01:32<00:00,  9.83it/s]\n"
     ]
    }
   ],
   "source": [
    "feats = np.zeros((len(ds), feat.shape[1]))\n",
    "i = 0\n",
    "for dat in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        dat = dat.to(device)\n",
    "        feat,_ = model(dat)\n",
    "        l = len(feat)\n",
    "        feats[i : i + l, :] = feat.cpu().detach().numpy()\n",
    "        i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29115, 512)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 29115\n"
     ]
    }
   ],
   "source": [
    "dists, idx = get_nbrs(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_preds_by_thrsh(dists, idx, thrsh=.6)\n",
    "preds = preds2pids(preds, pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551912704169234"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanf1(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:19<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_best, thrsh_best, preds_best = find_best(dists, idx, thrshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7721332223292326, 0.54)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best, thrsh_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/git/shopee-product-matching/output/trn0008/tensorboard_csv/0_0/checkpoints/epoch=10-step=3640.ckpt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {ckpt} {p_trained}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopee",
   "language": "python",
   "name": "shopee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
